{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchmin import least_squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple Example\n",
    "Third example from https://hernandis.me/2020/04/05/three-examples-of-nonlinear-least-squares-fitting-in-python-with-scipy.html"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def h(theta, x, y):\n",
    "    return theta[2] * (x - theta[0])**2 + theta[3] * (y - theta[1])**2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "xs = torch.linspace(-1, 1, 20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "ys = torch.linspace(-1, 1, 20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junchi/sp1/myenv/lib/python3.7/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "gridx, gridy = torch.meshgrid(xs, ys)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "x0 = 0.1; y0 = -0.15; a = 1; b = 2; noise = 0.1\n",
    "hs = h([x0, y0, a, b], gridx, gridy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "hs += noise * torch.rand(hs.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def fun(theta):\n",
    "    return (h(theta, gridx, gridy) - hs).flatten()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "theta0 = torch.tensor([1.0,2.0,3.0,4.0])\n",
    "print(theta0.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": " active_mask: tensor([0., 0., 0., 0.])\n        cost: tensor(0.2703)\n         fun: tensor([-1.7471e-03, -4.9572e-03,  6.7794e-02,  1.5046e-02,  8.8193e-03,\n         4.8228e-02,  4.8441e-02,  3.4462e-02, -9.0724e-03, -4.0262e-02,\n        -4.5632e-03,  3.6764e-02,  3.5071e-02, -3.2262e-02,  2.3600e-02,\n         6.5706e-03,  4.2486e-02,  1.6864e-02,  6.0347e-02,  1.0507e-01,\n         6.3286e-03,  2.8369e-02,  2.6200e-02,  1.5559e-02, -3.3913e-02,\n        -8.2383e-03, -5.9159e-03, -2.6908e-02, -1.6461e-02, -2.9558e-02,\n        -4.8771e-02,  4.3956e-02, -4.5494e-02,  1.7209e-03, -6.6527e-03,\n         3.5132e-02, -1.3797e-02,  5.4305e-02, -1.0414e-02,  3.1912e-03,\n         3.9157e-02,  1.0020e-03,  4.3786e-02, -2.9698e-02,  4.4659e-02,\n        -5.6294e-02,  2.7010e-02,  2.5887e-02, -3.7729e-02, -2.3957e-02,\n         2.4721e-02,  2.4408e-03, -2.1249e-02,  2.5176e-02, -1.4634e-02,\n         1.1047e-02,  2.2877e-02,  1.8584e-02,  4.0228e-02,  5.5419e-02,\n        -4.6577e-03,  4.4930e-02,  8.5616e-03,  6.7527e-03, -1.9099e-02,\n         1.7749e-02,  6.1814e-03, -3.5600e-03, -6.9301e-02,  1.6575e-02,\n        -2.5478e-02, -2.0740e-02, -1.9536e-02, -2.2865e-02, -8.7677e-03,\n         3.3641e-02, -9.1970e-03,  4.9304e-02, -1.8734e-02,  6.8186e-02,\n         4.9297e-02,  6.6698e-04, -5.1324e-02, -4.5948e-02, -5.4810e-03,\n        -6.6621e-02, -3.5109e-02,  2.6155e-03, -7.5600e-02, -5.5376e-02,\n        -1.6714e-02, -6.9314e-02, -3.2599e-02, -2.1927e-02, -3.4932e-02,\n         2.8924e-02, -4.9591e-04,  4.4889e-02, -1.8861e-02,  9.8968e-03,\n         3.8379e-02, -1.9284e-02,  7.6102e-03, -2.2381e-02,  2.3992e-02,\n        -4.0296e-02, -6.9830e-02, -8.0387e-02, -1.3117e-03,  2.7492e-03,\n         5.1510e-04, -7.1124e-02, -1.9123e-02, -4.5269e-02,  2.4327e-02,\n        -9.0176e-03,  2.8825e-02, -1.6799e-02,  1.3856e-02, -3.2237e-02,\n         4.4785e-02, -2.1362e-03, -4.1208e-02, -5.4107e-02, -7.3004e-02,\n        -6.4383e-02, -3.4200e-02, -4.5360e-02, -4.4046e-02, -7.1393e-02,\n        -4.0358e-02,  7.6221e-03, -1.0761e-02, -2.9293e-02, -6.6150e-02,\n        -6.6459e-02, -4.6984e-02,  7.2188e-03,  2.3525e-02, -4.1148e-02,\n         1.4722e-02, -4.9495e-02, -2.2115e-02, -4.3287e-02, -4.3932e-02,\n         3.2898e-03, -4.3894e-02, -4.8050e-02, -3.1590e-06, -6.1071e-02,\n        -3.4825e-02, -4.6707e-02, -1.3156e-03, -6.3323e-02, -6.4020e-02,\n        -2.0936e-02, -1.3039e-02, -1.1455e-02,  2.2553e-02, -1.8572e-02,\n         1.2554e-02, -5.7702e-02,  1.5226e-02, -6.4337e-02, -1.6503e-02,\n        -4.8821e-02, -5.7913e-02, -3.8898e-02, -3.8476e-02, -3.7899e-02,\n        -2.5458e-02, -8.2645e-02, -5.7532e-02,  3.0519e-03, -7.6194e-02,\n        -1.6298e-02, -2.9954e-02,  8.4639e-05, -1.3675e-02, -2.5843e-02,\n         2.2063e-02, -4.8200e-02, -6.1815e-02, -5.8609e-02, -3.6022e-03,\n        -2.2604e-02, -5.1019e-02, -6.5348e-02, -8.6979e-02, -5.7589e-02,\n        -7.3652e-03, -6.2321e-03, -4.1745e-02, -3.3040e-02, -7.3916e-02,\n        -5.3642e-02, -9.9800e-03, -5.2213e-02, -8.4243e-03,  5.2164e-03,\n         4.1136e-03,  1.5032e-02, -1.5682e-02,  1.4365e-02, -6.6135e-03,\n         4.7262e-03,  2.9327e-03, -3.4721e-02, -5.4772e-02, -6.0205e-02,\n        -1.7093e-02, -2.7987e-02, -1.9533e-02, -1.8997e-03, -2.1187e-02,\n        -6.5682e-02, -6.2700e-02, -5.8987e-02, -5.9056e-02,  3.0803e-02,\n         1.0744e-02, -2.1110e-02, -6.4752e-02, -1.3536e-02, -3.3380e-02,\n        -2.4399e-02, -9.9891e-03, -3.2369e-02, -6.0892e-04, -8.0736e-03,\n        -2.4816e-02, -1.1430e-02, -5.0837e-02,  2.4130e-03, -1.9764e-02,\n        -5.5462e-03,  2.3121e-02,  2.0920e-02,  1.4764e-02,  1.2459e-02,\n        -3.7730e-02,  3.1324e-02, -4.1693e-02, -3.5939e-03, -1.3625e-02,\n        -8.8703e-02, -6.9572e-02, -5.8125e-02, -1.7528e-03, -3.1299e-02,\n        -6.1431e-02, -8.6837e-03, -6.8523e-02, -6.6403e-02, -6.6990e-02,\n        -6.5119e-03,  1.6147e-02, -6.0580e-02, -5.8408e-03,  3.9283e-02,\n        -1.3201e-02,  6.5274e-03, -3.1043e-02,  1.1270e-02, -2.4498e-02,\n        -5.1811e-02, -7.7321e-02, -6.3908e-02, -5.3058e-02,  5.0276e-03,\n        -4.5194e-02, -4.0962e-02, -3.2539e-02, -4.9361e-02, -5.8729e-02,\n        -3.6684e-02, -1.1469e-02, -1.9558e-02, -9.6860e-03,  3.3140e-02,\n        -2.4456e-03, -3.6065e-02, -6.2015e-02, -6.8604e-02, -3.0872e-02,\n        -1.4918e-02, -3.6102e-02, -8.8977e-03, -4.2770e-02, -2.1127e-02,\n        -5.2463e-02, -8.3514e-02, -3.5498e-02, -4.2823e-02, -5.3491e-02,\n        -1.1515e-02, -5.9932e-02, -7.4887e-03,  1.4913e-02,  3.4958e-02,\n         4.6856e-02,  3.6803e-02, -5.0793e-02, -2.9133e-02, -6.5385e-02,\n        -1.0915e-02,  1.4893e-02, -3.0313e-02, -5.7385e-02, -1.5294e-02,\n        -1.7174e-02, -6.5814e-02, -7.4435e-02, -2.4841e-02,  8.3692e-03,\n         7.2081e-03, -2.9515e-02, -6.1882e-03,  5.1269e-02,  5.1978e-02,\n         5.0647e-02,  1.6312e-02, -2.4590e-02, -3.8106e-03, -2.7056e-03,\n         6.4994e-03,  1.3652e-02, -7.0785e-03, -7.1748e-02,  1.7535e-02,\n         8.4897e-03, -1.0366e-03, -9.2779e-03, -1.9175e-02,  2.7188e-02,\n         3.6707e-02,  4.0831e-02,  2.3634e-02,  4.3159e-02,  3.6464e-02,\n         4.7448e-02, -1.6225e-02, -2.1813e-02, -7.5064e-03,  1.6968e-02,\n        -4.3973e-02,  1.8364e-02, -6.7562e-02, -5.2518e-02, -4.8180e-02,\n        -2.8429e-02,  8.9166e-03,  3.2486e-02, -4.1002e-02, -2.8175e-02,\n         3.0715e-02,  2.6106e-02, -2.8169e-02,  3.9013e-02, -3.1450e-03,\n         4.9290e-02, -3.3954e-03,  4.1939e-02,  3.3975e-03, -6.2765e-03,\n         2.3612e-02, -3.9986e-02,  7.8670e-03,  3.0600e-03, -1.8444e-02,\n         6.7318e-03, -9.0373e-03, -1.2520e-02,  1.5443e-02, -1.7845e-02,\n        -2.7890e-02,  9.0184e-03,  2.5568e-03, -1.5829e-02,  8.5211e-03,\n        -5.8024e-03, -8.1203e-03, -1.4023e-02,  2.1951e-02,  3.1725e-02,\n         5.9580e-03, -1.3098e-02,  2.6398e-03, -3.9846e-02,  2.7898e-02,\n        -3.0501e-02, -2.3256e-02,  1.6489e-02,  8.7639e-03,  4.8273e-02,\n         1.0622e-02,  1.6147e-02, -1.1315e-03,  1.7294e-02,  5.2798e-03])\n        grad: tensor([-1.1400e-04, -7.7486e-05,  5.5656e-06,  4.1127e-06])\n         jac: <torchmin.lstsq.linear_operator.TorchLinearOperator object at 0x7ff7182d8c50>\n     message: '`xtol` termination condition is satisfied.'\n        nfev: 15\n        njev: 11\n  optimality: tensor(0.0001)\n      status: 3\n     success: True\n           x: tensor([ 0.0964, -0.1483,  1.0542,  2.0430])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "least_squares(fun, theta0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Homography Estimation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "h_gt = torch.tensor([[1,0,10],\n",
    "                     [0,1,5],\n",
    "                     [0,0,1]]).float()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junchi/sp1/myenv/lib/python3.7/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# sample points\n",
    "xs = torch.linspace(0, 40-1, 40)\n",
    "ys = torch.linspace(0, 30-1, 30)\n",
    "gridx, gridy = torch.meshgrid(xs, ys)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 40, 30])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([0., 5.])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_pts = torch.stack([gridx, gridy])\n",
    "print(src_pts.shape)\n",
    "src_pts[:,0,5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "src_pts = torch.concat((src_pts, torch.ones(src_pts.shape[1:])[None, :, :]), dim=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 40, 30])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([0., 5., 1.])"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(src_pts.shape)\n",
    "src_pts[:,0,5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def apply_homography(H, pts_src):\n",
    "    pts_dst = H @ pts_src\n",
    "    pts_dst = pts_dst / pts_dst[-1, :]\n",
    "    return pts_dst"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1200])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([10., 15.,  1.])"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_pts = src_pts.reshape(3, -1)\n",
    "dst_pts =  apply_homography(h_gt, src_pts)\n",
    "print(dst_pts.shape)\n",
    "dst_pts[:,10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([10.0974, 15.0206,  1.1000])"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = 0.1\n",
    "dst_pts += noise * torch.rand(dst_pts.shape)\n",
    "dst_pts[:,10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def fun(theta):\n",
    "    theta = torch.cat([theta, torch.ones(1)])\n",
    "    r = (apply_homography(theta.reshape(3,3), src_pts) - dst_pts)\n",
    "    return r.flatten()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  0., 10.,  0.,  1.,  5.,  0.,  0.,  1.])\n",
      "tensor([[ 1.,  0., 10.],\n",
      "        [ 0.,  1.,  5.],\n",
      "        [ 0.,  0.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "theta = torch.tensor([1,0,10,0,1,5,0,0])\n",
    "theta = torch.cat([theta, torch.ones(1)])\n",
    "print(theta)\n",
    "print(theta.reshape(3,3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1., 0., 0., 0., 1., 0., 0., 0.])"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta0 = torch.eye(3).flatten()[:-1]\n",
    "# theta0 = torch.tensor([1,0,11.0,0,1,6,0,0]).float()\n",
    "theta0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3600])\n"
     ]
    }
   ],
   "source": [
    "theta = torch.tensor([1,0,10,0,1,5,0,0])\n",
    "r = fun(theta)\n",
    "print(r.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "dst_pts = dst_pts\n",
    "src_pts = src_pts\n",
    "theta0 = theta0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = fun(theta0)\n",
    "r.device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "import torchimize\n",
    "from torchimize.functions import lsq_gna\n",
    "from torchimize.functions import lsq_lma\n",
    "\n",
    "coeffs_list = lsq_lma(theta0, fun)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([1., 0., 0., 0., 1., 0., 0., 0.]),\n tensor([ 1.0505,  0.0693,  0.0062,  0.0255,  1.0041,  0.0024, -0.0052, -0.0052]),\n tensor([ 1.1186,  0.1448,  0.0144,  0.0686,  1.0347,  0.0066, -0.0024, -0.0025]),\n tensor([ 1.2161e+00,  2.3459e-01,  2.7815e-02,  1.1833e-01,  1.0990e+00,\n          1.3860e-02,  1.8550e-05, -1.0914e-04]),\n tensor([1.3651, 0.3355, 0.0529, 0.1628, 1.2334, 0.0271, 0.0029, 0.0036]),\n tensor([1.5401, 0.4301, 0.0972, 0.1872, 1.4227, 0.0471, 0.0060, 0.0083]),\n tensor([1.6840, 0.5072, 0.1798, 0.1964, 1.5979, 0.0741, 0.0084, 0.0127]),\n tensor([1.7533, 0.5467, 0.3623, 0.1983, 1.6928, 0.1177, 0.0097, 0.0151]),\n tensor([1.7455, 0.5355, 0.8327, 0.1944, 1.6965, 0.2277, 0.0097, 0.0152]),\n tensor([1.7455, 0.5355, 0.8327, 0.1944, 1.6965, 0.2277, 0.0097, 0.0152]),\n tensor([1.7430, 0.5367, 0.8217, 0.1907, 1.6931, 0.3394, 0.0097, 0.0152]),\n tensor([1.7430, 0.5367, 0.8217, 0.1907, 1.6931, 0.3394, 0.0097, 0.0152]),\n tensor([1.7092, 0.5089, 1.2936, 0.1850, 1.6637, 0.4497, 0.0093, 0.0145]),\n tensor([1.7092, 0.5089, 1.2936, 0.1850, 1.6637, 0.4497, 0.0093, 0.0145]),\n tensor([1.7092, 0.5089, 1.2936, 0.1850, 1.6637, 0.4497, 0.0093, 0.0145]),\n tensor([1.6941, 0.4970, 1.4687, 0.1823, 1.6500, 0.4928, 0.0091, 0.0141]),\n tensor([1.6561, 0.4667, 1.9659, 0.1754, 1.6160, 0.6314, 0.0086, 0.0133]),\n tensor([1.6561, 0.4667, 1.9659, 0.1754, 1.6160, 0.6314, 0.0086, 0.0133]),\n tensor([1.6561, 0.4667, 1.9659, 0.1754, 1.6160, 0.6314, 0.0086, 0.0133]),\n tensor([1.6398, 0.4542, 2.1502, 0.1723, 1.6012, 0.6853, 0.0084, 0.0129]),\n tensor([1.6398, 0.4542, 2.1502, 0.1723, 1.6012, 0.6853, 0.0084, 0.0129]),\n tensor([1.6184, 0.4376, 2.4190, 0.1682, 1.5819, 0.7689, 0.0081, 0.0124]),\n tensor([1.6184, 0.4376, 2.4190, 0.1682, 1.5819, 0.7689, 0.0081, 0.0124]),\n tensor([1.5881, 0.4141, 2.8044, 0.1621, 1.5544, 0.8988, 0.0077, 0.0118]),\n tensor([1.5857, 0.4128, 2.8040, 0.1616, 1.5520, 0.8986, 0.0077, 0.0117]),\n tensor([1.5857, 0.4128, 2.8040, 0.1616, 1.5520, 0.8986, 0.0077, 0.0117]),\n tensor([1.5857, 0.4128, 2.8040, 0.1616, 1.5520, 0.8986, 0.0077, 0.0117]),\n tensor([1.5546, 0.3887, 3.2176, 0.1550, 1.5239, 1.0497, 0.0073, 0.0110]),\n tensor([1.5546, 0.3887, 3.2176, 0.1550, 1.5239, 1.0497, 0.0073, 0.0110]),\n tensor([1.5546, 0.3887, 3.2176, 0.1550, 1.5239, 1.0497, 0.0073, 0.0110]),\n tensor([1.5413, 0.3787, 3.3707, 0.1521, 1.5116, 1.1073, 0.0071, 0.0107]),\n tensor([1.5413, 0.3787, 3.3707, 0.1521, 1.5116, 1.1073, 0.0071, 0.0107]),\n tensor([1.5234, 0.3652, 3.5939, 0.1482, 1.4952, 1.1949, 0.0069, 0.0103]),\n tensor([1.5234, 0.3652, 3.5939, 0.1482, 1.4952, 1.1949, 0.0069, 0.0103]),\n tensor([1.4979, 0.3461, 3.9140, 0.1424, 1.4719, 1.3274, 0.0065, 0.0098]),\n tensor([1.4979, 0.3461, 3.9140, 0.1424, 1.4719, 1.3274, 0.0065, 0.0098]),\n tensor([1.4979, 0.3461, 3.9140, 0.1424, 1.4719, 1.3274, 0.0065, 0.0098]),\n tensor([1.4875, 0.3385, 4.0327, 0.1400, 1.4622, 1.3775, 0.0064, 0.0096]),\n tensor([1.4693, 0.3197, 4.3554, 0.1398, 1.4474, 1.3488, 0.0062, 0.0091]),\n tensor([1.4682, 0.3189, 4.3553, 0.1397, 1.4461, 1.3486, 0.0062, 0.0090]),\n tensor([1.4682, 0.3189, 4.3553, 0.1397, 1.4461, 1.3486, 0.0062, 0.0090]),\n tensor([1.4682, 0.3189, 4.3553, 0.1397, 1.4461, 1.3486, 0.0062, 0.0090]),\n tensor([1.4682, 0.3189, 4.3553, 0.1397, 1.4461, 1.3486, 0.0062, 0.0090]),\n tensor([1.4644, 0.3162, 4.4018, 0.1387, 1.4426, 1.3727, 0.0062, 0.0090]),\n tensor([1.4534, 0.3083, 4.5381, 0.1358, 1.4323, 1.4444, 0.0060, 0.0087]),\n tensor([1.4534, 0.3083, 4.5381, 0.1358, 1.4323, 1.4444, 0.0060, 0.0087]),\n tensor([1.4371, 0.2967, 4.7362, 0.1314, 1.4170, 1.5506, 0.0058, 0.0084]),\n tensor([1.4361, 0.2962, 4.7361, 0.1312, 1.4161, 1.5505, 0.0058, 0.0084]),\n tensor([1.4361, 0.2962, 4.7361, 0.1312, 1.4161, 1.5505, 0.0058, 0.0084]),\n tensor([1.4361, 0.2962, 4.7361, 0.1312, 1.4161, 1.5505, 0.0058, 0.0084]),\n tensor([1.4189, 0.2839, 4.9516, 0.1266, 1.4000, 1.6687, 0.0056, 0.0080]),\n tensor([1.4189, 0.2839, 4.9516, 0.1266, 1.4000, 1.6687, 0.0056, 0.0080]),\n tensor([1.4179, 0.2834, 4.9515, 0.1264, 1.3990, 1.6686, 0.0055, 0.0080]),\n tensor([1.4179, 0.2834, 4.9515, 0.1264, 1.3990, 1.6686, 0.0055, 0.0080]),\n tensor([1.4179, 0.2834, 4.9515, 0.1264, 1.3990, 1.6686, 0.0055, 0.0080]),\n tensor([1.4084, 0.2766, 5.0709, 0.1238, 1.3901, 1.7347, 0.0054, 0.0078]),\n tensor([1.4078, 0.2763, 5.0708, 0.1237, 1.3896, 1.7347, 0.0054, 0.0078]),\n tensor([1.4078, 0.2763, 5.0708, 0.1237, 1.3896, 1.7347, 0.0054, 0.0078]),\n tensor([1.4078, 0.2763, 5.0708, 0.1237, 1.3896, 1.7347, 0.0054, 0.0078]),\n tensor([1.3974, 0.2689, 5.2021, 0.1208, 1.3798, 1.8084, 0.0053, 0.0076]),\n tensor([1.3974, 0.2689, 5.2021, 0.1208, 1.3798, 1.8084, 0.0053, 0.0076]),\n tensor([1.3817e+00, 2.5790e-01, 5.3922e+00, 1.1644e-01, 1.3650e+00, 1.9171e+00,\n         5.0701e-03, 7.2842e-03]),\n tensor([1.3817e+00, 2.5790e-01, 5.3922e+00, 1.1644e-01, 1.3650e+00, 1.9171e+00,\n         5.0701e-03, 7.2842e-03]),\n tensor([1.3817e+00, 2.5790e-01, 5.3922e+00, 1.1644e-01, 1.3650e+00, 1.9171e+00,\n         5.0701e-03, 7.2842e-03]),\n tensor([1.3753e+00, 2.5355e-01, 5.4629e+00, 1.1470e-01, 1.3590e+00, 1.9577e+00,\n         4.9826e-03, 7.1537e-03]),\n tensor([1.3587e+00, 2.4189e-01, 5.6663e+00, 1.1004e-01, 1.3433e+00, 2.0768e+00,\n         4.7625e-03, 6.8218e-03]),\n tensor([1.3587e+00, 2.4189e-01, 5.6663e+00, 1.1004e-01, 1.3433e+00, 2.0768e+00,\n         4.7625e-03, 6.8218e-03]),\n tensor([1.3587e+00, 2.4189e-01, 5.6663e+00, 1.1004e-01, 1.3433e+00, 2.0768e+00,\n         4.7625e-03, 6.8218e-03]),\n tensor([1.3519e+00, 2.3729e-01, 5.7417e+00, 1.0816e-01, 1.3369e+00, 2.1212e+00,\n         4.6695e-03, 6.6841e-03]),\n tensor([1.3472e+00, 2.3749e-01, 5.7329e+00, 1.0425e-01, 1.3312e+00, 2.2345e+00,\n         4.5609e-03, 6.6464e-03]),\n tensor([1.3469e+00, 2.3746e-01, 5.7329e+00, 1.0417e-01, 1.3311e+00, 2.2345e+00,\n         4.5550e-03, 6.6435e-03]),\n tensor([1.3469e+00, 2.3746e-01, 5.7329e+00, 1.0417e-01, 1.3311e+00, 2.2345e+00,\n         4.5550e-03, 6.6435e-03]),\n tensor([1.3469e+00, 2.3746e-01, 5.7329e+00, 1.0417e-01, 1.3311e+00, 2.2345e+00,\n         4.5550e-03, 6.6435e-03]),\n tensor([1.3396e+00, 2.5202e-01, 5.7191e+00, 9.7030e-02, 1.3438e+00, 2.2906e+00,\n         4.3115e-03, 7.1481e-03]),\n tensor([1.3335e+00, 2.3104e-01, 5.8707e+00, 9.8877e-02, 1.3197e+00, 2.3666e+00,\n         4.3533e-03, 6.4571e-03]),\n tensor([1.3335e+00, 2.3104e-01, 5.8707e+00, 9.8877e-02, 1.3197e+00, 2.3666e+00,\n         4.3533e-03, 6.4571e-03]),\n tensor([1.3296e+00, 2.2993e-01, 5.8631e+00, 9.5941e-02, 1.3134e+00, 2.4625e+00,\n         4.2699e-03, 6.3801e-03]),\n tensor([1.3296e+00, 2.2993e-01, 5.8631e+00, 9.5941e-02, 1.3134e+00, 2.4625e+00,\n         4.2699e-03, 6.3801e-03]),\n tensor([1.3296e+00, 2.2993e-01, 5.8631e+00, 9.5941e-02, 1.3134e+00, 2.4625e+00,\n         4.2699e-03, 6.3801e-03]),\n tensor([1.3231e+00, 2.2502e-01, 5.9496e+00, 9.4360e-02, 1.3074e+00, 2.5016e+00,\n         4.1881e-03, 6.2450e-03]),\n tensor([1.3231e+00, 2.2502e-01, 5.9496e+00, 9.4360e-02, 1.3074e+00, 2.5016e+00,\n         4.1881e-03, 6.2450e-03]),\n tensor([1.3135e+00, 2.1784e-01, 6.0756e+00, 9.2014e-02, 1.2985e+00, 2.5600e+00,\n         4.0678e-03, 6.0465e-03]),\n tensor([1.3135e+00, 2.1784e-01, 6.0756e+00, 9.2014e-02, 1.2985e+00, 2.5600e+00,\n         4.0678e-03, 6.0465e-03]),\n tensor([1.2997e+00, 2.0755e-01, 6.2565e+00, 8.8558e-02, 1.2856e+00, 2.6467e+00,\n         3.8932e-03, 5.7614e-03]),\n tensor([1.2997e+00, 2.0755e-01, 6.2565e+00, 8.8558e-02, 1.2856e+00, 2.6467e+00,\n         3.8932e-03, 5.7614e-03]),\n tensor([1.2990e+00, 2.0722e-01, 6.2564e+00, 8.8433e-02, 1.2850e+00, 2.6466e+00,\n         3.8811e-03, 5.7440e-03]),\n tensor([1.2990e+00, 2.0722e-01, 6.2564e+00, 8.8433e-02, 1.2850e+00, 2.6466e+00,\n         3.8811e-03, 5.7440e-03]),\n tensor([1.2990e+00, 2.0722e-01, 6.2564e+00, 8.8433e-02, 1.2850e+00, 2.6466e+00,\n         3.8811e-03, 5.7440e-03]),\n tensor([1.2916e+00, 2.0170e-01, 6.3560e+00, 8.6544e-02, 1.2781e+00, 2.6953e+00,\n         3.7887e-03, 5.5937e-03]),\n tensor([1.2916e+00, 2.0170e-01, 6.3560e+00, 8.6544e-02, 1.2781e+00, 2.6953e+00,\n         3.7887e-03, 5.5937e-03]),\n tensor([1.2806e+00, 1.9357e-01, 6.4999e+00, 8.3709e-02, 1.2677e+00, 2.7675e+00,\n         3.6491e-03, 5.3690e-03]),\n tensor([1.2806e+00, 1.9357e-01, 6.4999e+00, 8.3709e-02, 1.2677e+00, 2.7675e+00,\n         3.6491e-03, 5.3690e-03]),\n tensor([1.2806e+00, 1.9357e-01, 6.4999e+00, 8.3709e-02, 1.2677e+00, 2.7675e+00,\n         3.6491e-03, 5.3690e-03]),\n tensor([1.2762e+00, 1.9042e-01, 6.5532e+00, 8.2583e-02, 1.2636e+00, 2.7945e+00,\n         3.5916e-03, 5.2782e-03]),\n tensor([1.2644e+00, 1.8184e-01, 6.7064e+00, 7.9504e-02, 1.2526e+00, 2.8742e+00,\n         3.4429e-03, 5.0413e-03]),\n tensor([1.2644e+00, 1.8184e-01, 6.7064e+00, 7.9504e-02, 1.2526e+00, 2.8742e+00,\n         3.4429e-03, 5.0413e-03]),\n tensor([1.2644e+00, 1.8184e-01, 6.7064e+00, 7.9504e-02, 1.2526e+00, 2.8742e+00,\n         3.4429e-03, 5.0413e-03]),\n tensor([1.2598e+00, 1.7851e-01, 6.7631e+00, 7.8282e-02, 1.2482e+00, 2.9040e+00,\n         3.3817e-03, 4.9454e-03]),\n tensor([1.2473e+00, 1.6947e-01, 6.9250e+00, 7.4939e-02, 1.2365e+00, 2.9914e+00,\n         3.2233e-03, 4.6959e-03]),\n tensor([1.2468e+00, 1.6924e-01, 6.9250e+00, 7.4841e-02, 1.2361e+00, 2.9913e+00,\n         3.2142e-03, 4.6834e-03])]"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.6 s, sys: 0 ns, total: 21.6 s\n",
      "Wall time: 2.76 s\n"
     ]
    },
    {
     "data": {
      "text/plain": " active_mask: tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n        cost: tensor(2.9713)\n         fun: tensor([-0.0451,  0.0429,  0.0248,  ..., -0.0292, -0.0981, -0.0606])\n        grad: tensor([-0.0033, -0.0013, -0.1134, -0.0134,  0.0120, -0.0833,  1.1609,  0.8150])\n         jac: <torchmin.lstsq.linear_operator.TorchLinearOperator object at 0x7f934d9f3ed0>\n     message: '`xtol` termination condition is satisfied.'\n        nfev: 440\n        njev: 434\n  optimality: tensor(1.1609)\n      status: 3\n     success: True\n           x: tensor([ 1.0001e+00, -4.3697e-04,  1.0053e+01,  2.7896e-05,  9.9963e-01,\n         5.0505e+00,  4.9899e-06, -1.3778e-05])"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "least_squares(fun, theta0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.optimize.optimize.OptimizeResult'>\n"
     ]
    },
    {
     "data": {
      "text/plain": " active_mask: tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n        cost: tensor(2.9045, device='cuda:0')\n         fun: tensor([-0.0025,  0.0137,  0.0036,  ..., -0.0176, -0.0534, -0.0486],\n       device='cuda:0')\n        grad: tensor([ 0.0434,  0.0162, -0.1346,  0.0444,  0.0527, -0.0974, -1.3460, -0.8048],\n       device='cuda:0')\n         jac: <torchmin.lstsq.linear_operator.TorchLinearOperator object at 0x7ff7182ff8d0>\n     message: '`xtol` termination condition is satisfied.'\n        nfev: 705\n        njev: 698\n  optimality: tensor(1.3460, device='cuda:0')\n      status: 3\n     success: True\n           x: tensor([ 1.0004e+00, -5.3274e-05,  1.0048e+01,  2.1995e-05,  1.0003e+00,\n         5.0490e+00,  4.7323e-06,  2.5037e-06], device='cuda:0')"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(res))\n",
    "res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 1.0004e+00, -5.3274e-05,  1.0048e+01,  2.1995e-05,  1.0003e+00,\n         5.0490e+00,  4.7323e-06,  2.5037e-06], device='cuda:0')"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.x.device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def compute_homography(reference_points, observed_points):\n",
    "    # Initialize the homography parameters to some initial values\n",
    "    h = torch.tensor([[1.0, 0.0, 0.0],\n",
    "                      [0.0, 1.0, 0.0],\n",
    "                      [0.0, 0.0, 1.0]], dtype=torch.float)\n",
    "\n",
    "    h = torch.autograd.Variable(h).requires_grad_()\n",
    "\n",
    "    # Define a function that computes the residuals\n",
    "    def residuals(h):\n",
    "        # Transform the reference points using the homography\n",
    "        transformed_points = torch.matmul(h, reference_points)\n",
    "\n",
    "        # Divide the transformed points by their third coordinate to normalize them\n",
    "        transformed_points = transformed_points / transformed_points[2,:]\n",
    "\n",
    "        # Compute the residuals as the difference between the observed points\n",
    "        # and the transformed points\n",
    "        residuals = observed_points - transformed_points\n",
    "\n",
    "        # Enable gradient tracking for the residuals tensor\n",
    "        residuals.requires_grad_()\n",
    "\n",
    "        mse = torch.mean(residuals ** 2)\n",
    "\n",
    "        # Return the MSE as a scalar tensor\n",
    "        return mse\n",
    "\n",
    "    # Define a function that computes the Jacobian matrix\n",
    "    def jacobian(h):\n",
    "        # Compute the Jacobian matrix of the residuals with respect to the homography parameters\n",
    "        # This can be computed analytically, but for simplicity we will approximate it\n",
    "        # by finite differences using the torch.autograd module\n",
    "        with torch.enable_grad():\n",
    "            h_grad = torch.autograd.grad(residuals(h), h, create_graph=True)\n",
    "\n",
    "        # Reshape the tensor of gradients into a 2D tensor\n",
    "        jacobian = torch.reshape(torch.stack(h_grad), (3, 3))\n",
    "\n",
    "        # Return the Jacobian matrix as a tensor\n",
    "        return jacobian\n",
    "\n",
    "    # Define a stopping criterion (e.g., maximum number of iterations or convergence tolerance)\n",
    "    max_iter = 100\n",
    "    tol = 1e-6\n",
    "\n",
    "    # Iterate until the stopping criterion is met\n",
    "    for i in range(max_iter):\n",
    "        # Compute the residuals and the Jacobian matrix\n",
    "        r = residuals(h)\n",
    "        j = jacobian(h)\n",
    "\n",
    "        # Solve the linear system of equations using the Gaussian elimination method\n",
    "        # This can be done using the torch.solve() function\n",
    "        h_update, _ = torch.linalg.solve(r, j)\n",
    "\n",
    "        # Update the homography parameters\n",
    "        h = h + h_update\n",
    "\n",
    "        # Check the stopping criterion\n",
    "        if torch.norm(h_update) < tol:\n",
    "            break\n",
    "\n",
    "    # Return the estimated homography matrix\n",
    "    return h"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "linalg.solve: The input tensor must have at least 2 dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_7933/912384654.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;31m# Compute the homography matrix using the compute_homography() function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m \u001B[0mh\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompute_homography\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreference_points\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mT\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mobserved_points\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mT\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0;31m# Print the resulting homography matrix\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_7933/2664731588.py\u001B[0m in \u001B[0;36mcompute_homography\u001B[0;34m(reference_points, observed_points)\u001B[0m\n\u001B[1;32m     53\u001B[0m         \u001B[0;31m# Solve the linear system of equations using the Gaussian elimination method\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     54\u001B[0m         \u001B[0;31m# This can be done using the torch.solve() function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 55\u001B[0;31m         \u001B[0mh_update\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinalg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msolve\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mj\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     56\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     57\u001B[0m         \u001B[0;31m# Update the homography parameters\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: linalg.solve: The input tensor must have at least 2 dimensions."
     ]
    }
   ],
   "source": [
    "# Define some test points in the reference coordinate system\n",
    "reference_points = torch.tensor([[1.0, 1.0, 1.0],\n",
    "                                 [1.0, 2.0, 1.0],\n",
    "                                 [2.0, 1.0, 1.0],\n",
    "                                 [2.0, 2.0, 1.0]], dtype=torch.float, requires_grad=True)\n",
    "\n",
    "# Define the corresponding points in the observed coordinate system\n",
    "observed_points = torch.tensor([[2.0, 1.0, 1.0],\n",
    "                                [2.0, 3.0, 1.0],\n",
    "                                [3.0, 1.0, 1.0],\n",
    "                                [3.0, 3.0, 1.0]], dtype=torch.float)\n",
    "\n",
    "# Compute the homography matrix using the compute_homography() function\n",
    "h = compute_homography(reference_points.T, observed_points.T)\n",
    "\n",
    "# Print the resulting homography matrix\n",
    "print(h)\n",
    "\n",
    "# The expected output is:\n",
    "# tensor([[1., 0., 1.],\n",
    "#         [0., 1., 1.],\n",
    "#         [0., 0., 1.]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def gauss_newton(X, Y, max_iters=100):\n",
    "  # Initialize the homography matrix H to the identity matrix\n",
    "  H = np.eye(3)\n",
    "\n",
    "  # Repeat the Gauss-Newton algorithm for a maximum number of iterations\n",
    "  for _ in range(max_iters):\n",
    "    # Compute the error between the points and the transformed points\n",
    "    error = Y - np.dot(X, H.T)\n",
    "\n",
    "    # Compute the Jacobian matrix\n",
    "    J = np.zeros((len(X), 8))\n",
    "    for i in range(len(X)):\n",
    "      J[i] = [-X[i, 0], -X[i, 1], -1, 0, 0, 0, X[i, 0]*error[i, 0], X[i, 1]*error[i, 0]]\n",
    "      J[i] = [0, 0, 0, -X[i, 0], -X[i, 1], -1, X[i, 0]*error[i, 1], X[i, 1]*error[i, 1]]\n",
    "\n",
    "    # Compute the Hessian matrix and the gradient vector\n",
    "    H = np.dot(J.T, J)\n",
    "    g = np.dot(J.T, error.flatten())\n",
    "\n",
    "    # Solve for the update vector using the Cholesky decomposition\n",
    "    L = np.linalg.cholesky(H)\n",
    "    delta = np.linalg.solve(L.T, np.linalg.solve(L, g))\n",
    "\n",
    "    # Update the homography matrix\n",
    "    H += delta.reshape((3, 3))\n",
    "\n",
    "  return H"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (8,10) and (30,) not aligned: 10 (dim 1) != 30 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_7933/3176036830.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;31m# Compute the homography matrix using the Gauss-Newton method\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0mH\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgauss_newton\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_7933/531772556.py\u001B[0m in \u001B[0;36mgauss_newton\u001B[0;34m(X, Y, max_iters)\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[0;31m# Compute the Hessian matrix and the gradient vector\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[0mH\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mJ\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mT\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mJ\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m     \u001B[0mg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mJ\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mT\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merror\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     20\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m     \u001B[0;31m# Solve for the update vector using the Cholesky decomposition\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<__array_function__ internals>\u001B[0m in \u001B[0;36mdot\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: shapes (8,10) and (30,) not aligned: 10 (dim 1) != 30 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Generate some random points in the two images\n",
    "# Generate some random points in the two images\n",
    "X = np.random.rand(10, 3)\n",
    "Y = np.random.rand(10, 3)\n",
    "\n",
    "# Compute the homography matrix using the Gauss-Newton method\n",
    "H = gauss_newton(X, Y)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
